from sagemaker.huggingface.model import HuggingFaceModel
from sagemaker.async_inference.async_inference_config import AsyncInferenceConfig
from sagemaker.s3 import s3_path_join
from sagemaker.serializers import DataSerializer
import sagemaker
import boto3

sess = sagemaker.Session()
# sagemaker session bucket -> used for uploading data, models and logs
# sagemaker will automatically create this bucket if it not exists
sagemaker_session_bucket=None
if sagemaker_session_bucket is None and sess is not None:
    # set to default bucket if a bucket name is not given
    sagemaker_session_bucket = sess.default_bucket()

try:
    role = sagemaker.get_execution_role()
except ValueError:
    iam = boto3.client('iam')
    role = iam.get_role(RoleName='AmazonSageMaker-ExecutionRole-20240602T154691')['Role']['Arn']

sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)

print(f"sagemaker role arn: {role}")
print(f"sagemaker bucket: {sess.default_bucket()}")
print(f"sagemaker session region: {sess.boto_region_name}")


# Hub Model configuration. <https://huggingface.co/models>
hub = {
    'HF_MODEL_ID': 'ivrit-ai/whisper-large-v2-tuned',
    'HF_TASK': 'automatic-speech-recognition',
    "chunk_length_s": "30",
    'MMS_MAX_REQUEST_SIZE': '2000000000',
    'MMS_MAX_RESPONSE_SIZE': '2000000000',
    'MMS_DEFAULT_RESPONSE_TIMEOUT': '900'
}

# create Hugging Face Model Class
huggingface_model = HuggingFaceModel(
    env=hub,  # configuration for loading model from Hub
    role=role,  # iam role with permissions to create an Endpoint
    transformers_version="4.37.0",  # transformers version used
    pytorch_version="2.1.0",  # pytorch version used
    py_version='py310',  # python version used
)

# create async endpoint configuration
async_config = AsyncInferenceConfig(
    output_path=s3_path_join("s3://", sagemaker_session_bucket, "async_inference/output"),
    # Where our results will be stored
    # notification_config={
    #   "SuccessTopic": "arn:aws:sns:us-east-2:123456789012:MyTopic",
    #   "ErrorTopic": "arn:aws:sns:us-east-2:123456789012:MyTopic",
    # }, #  Notification configuration
)

audio_serializer = DataSerializer(content_type='audio/x-audio')

# deploy the endpoint
huggingface_model.deploy(
    initial_instance_count=1,
    instance_type="ml.m5.xlarge",  # ml.g4dn.xlarge,
    async_inference_config=async_config,
    serializer=audio_serializer
)
